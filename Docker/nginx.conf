# Docker/nginx.conf
events {
    worker_connections 1024;
}

http {
    upstream ats_api {
        server ats-scorer-api:8000;
    }

    server {
        listen 80;
        server_name localhost;

        location / {
            proxy_pass http://ats_api;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Handle file uploads
            client_max_body_size 10M;
        }

        location /static/ {
            alias /usr/share/nginx/html/static/;
        }

        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
    }
}

---

# Docker/init-db.sql
-- Initialize database for ATS Resume Scorer

-- Create tables for storing scoring results
CREATE TABLE IF NOT EXISTS scoring_results (
    id SERIAL PRIMARY KEY,
    filename VARCHAR(255) NOT NULL,
    overall_score DECIMAL(5,2) NOT NULL,
    grade CHAR(1) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    job_description_hash VARCHAR(64),
    detailed_scores JSONB,
    recommendations TEXT[]
);

-- Create table for job descriptions
CREATE TABLE IF NOT EXISTS job_descriptions (
    id SERIAL PRIMARY KEY,
    title VARCHAR(255),
    company VARCHAR(255),
    content_hash VARCHAR(64) UNIQUE,
    content TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    required_skills TEXT[],
    preferred_skills TEXT[]
);

-- Create table for resume metadata
CREATE TABLE IF NOT EXISTS resume_metadata (
    id SERIAL PRIMARY KEY,
    filename VARCHAR(255) NOT NULL,
    file_hash VARCHAR(64) UNIQUE,
    file_size INTEGER,
    file_type VARCHAR(10),
    skills_extracted TEXT[],
    experience_count INTEGER,
    education_count INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes for better performance
CREATE INDEX IF NOT EXISTS idx_scoring_results_filename ON scoring_results(filename);
CREATE INDEX IF NOT EXISTS idx_scoring_results_created_at ON scoring_results(created_at);
CREATE INDEX IF NOT EXISTS idx_job_descriptions_hash ON job_descriptions(content_hash);
CREATE INDEX IF NOT EXISTS idx_resume_metadata_hash ON resume_metadata(file_hash);

-- Insert sample data
INSERT INTO job_descriptions (title, company, content_hash, content, required_skills, preferred_skills) 
VALUES (
    'Senior Python Developer',
    'TechCorp',
    'sample_hash_123',
    'We are looking for a Senior Python Developer...',
    ARRAY['python', 'django', 'sql', 'git'],
    ARRAY['aws', 'docker', 'react']
) ON CONFLICT (content_hash) DO NOTHING;

---

# Docker/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'ats-scorer-api'
    static_configs:
      - targets: ['ats-scorer-api:8000']
    metrics_path: '/metrics'
    scrape_interval: 30s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']

---

# Docker/.dockerignore
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual environments
.venv/
venv/
ENV/
env/

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Logs
*.log

# Test coverage
htmlcov/
.coverage
.pytest_cache/

# Git
.git/
.gitignore

# Documentation
docs/_build/

# Temporary files
*.tmp
*.temp
temp/

# Large test files
tests/fixtures/large_files/

---

# Docker/docker-entrypoint.sh
#!/bin/bash
set -e

# Wait for database to be ready
if [ "$DATABASE_URL" ]; then
    echo "Waiting for database..."
    while ! pg_isready -h postgres -p 5432 -U ats_user; do
        sleep 1
    done
    echo "Database is ready!"
fi

# Run database migrations if needed
if [ "$RUN_MIGRATIONS" = "true" ]; then
    echo "Running database setup..."
    python -c "
import psycopg2
import os
try:
    conn = psycopg2.connect(
        host='postgres',
        database='ats_scorer',
        user='ats_user',
        password='ats_password_2024'
    )
    print('Database connection successful')
    conn.close()
except Exception as e:
    print(f'Database connection failed: {e}')
"
fi

# Initialize application
echo "Initializing ATS Resume Scorer..."
python -c "from ats_resume_scorer.main import ATSResumeScorer; ATSResumeScorer()"

# Execute the main command
exec "$@"